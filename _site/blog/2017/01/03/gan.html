<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Using convolutional GANs for image making</title>
  <meta name="description" content="The first GAN was trained for 5,000 epochs on two classes containing 100 images each.Example of the ‘Ohio’ class:Example of the ‘Chicago’ class:After 1050 ep...">

  <!-- evil icon -->

  <link rel="stylesheet" href="/assets/evil-icons.min.css">
  <script src="/assets/evil-icons.min.js"></script>

  <!-- todo: include this into main.css -->

  <link rel="stylesheet" href="/css/main.css">
  <link rel="canonical" href="http://localhost:4000/blog/2017/01/03/gan.html">
  <link rel="alternate" type="application/rss+xml" title="Chris Martin" href="http://localhost:4000/feed.xml">
</head>

  <body>
    <div class="page-content">
      <div class="container">
        <div class="three columns">
          <header class="site-header">

  <h2 class="logo"><a href="/">Chris Martin</a></h2>

  <div class="nav">
    
    <label for="menu-toggle" class="menu-icon">
        <!--div data-icon="ei-navicon"></div-->
        <svg viewBox="0 0 18 15">
          <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
          <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
          <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
        </svg>
    </label>
    <input type="checkbox" id="menu-toggle">

    <div class="site-nav">
      <nav>
        <ul class="page-link">
          <li><a href="mailto:cmarti14@artic.edu">cmarti14@artic.edu</a></li>
          <li><a href="/Resume.pdf">Resume</a></li>
          <li><a href="https://github.com/ChristopherWMartin/">Github</a></li>
          <li><a href="/archive">Posts</a></li>
        </ul>
      </nav>
    </div>

  </div>
</header>

        </div>

        <div class="nine columns" style="z-index:100;">
          <div class="wrapper">
            <article class="post" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="artilce_header">
    <h1 class="artilce_title" itemprop="name headline">Using convolutional GANs for image making</h1>
    <p class="artilce_meta"><time datetime="2017-01-03T00:00:00-05:00" itemprop="datePublished">Jan 3, 2017</time></p>
  </header>

  <div class="article-content" itemprop="articleBody">
    <p>The first GAN was trained for 5,000 epochs on two classes containing 100 images each.</p>

<p>Example of the ‘Ohio’ class:</p>

<p><img src="/assets/img/ohio1.jpg" alt="" /></p>

<hr />

<p>Example of the ‘Chicago’ class:</p>

<p><img src="/assets/img/chicago1.jpg" alt="" /></p>

<hr />

<p>After 1050 epochs I was able to generate an image that could be understood as a landscape. I then asked the net to extrapolate the image into a panorama – the result is understandably repetitive.</p>

<p><img src="/assets/img/moving_InProgress1.png" alt="" /></p>

<hr />

<p>3,950 epochs later the resulting images are less of a Chicago+Ohio hybrid than a blending together of the images of each descrete class.</p>

<p><img src="/assets/img/1_ne1x_ne4x.png" alt="" /></p>

<hr />

<p><img src="/assets/img/2_ne1x_ne4x.png" alt="" /></p>

<hr />

<hr />

<p>Next, I trained a GAN for 5,600 epochs on 4,000 screen recorded frames of four different 3D models:</p>

<p>1</p>

<p><img src="/assets/img/3d1.png" alt="" /></p>

<hr />

<p>2</p>

<p><img src="/assets/img/3d2.png" alt="" /></p>

<hr />

<p>3</p>

<p><img src="/assets/img/3d3.png" alt="" /></p>

<hr />

<p>4</p>

<p><img src="/assets/img/3d4.png" alt="" /></p>

<hr />

<p>After 500 epochs:</p>

<p><img src="/assets/img/3d_InProgress.png" alt="" /></p>

<hr />

<p>The final result is much more clear than the landscape images:</p>

<p><img src="/assets/img/10_ne1x_ne4x.png" alt="" /></p>

<hr />

<hr />

<p>Most recently, I trained on 1,000 photographs of light fixtures shot against either a static grey or white background.</p>

<hr />

<p><img src="/assets/img/lighting1.jpg" alt="" /></p>

<hr />

<p><img src="/assets/img/lighting2.JPG" alt="" /></p>

<hr />

<p>It seems to be clear that better results can be obtained when the subject is against an unchanging surface as the GAN is unable to tell the difference between foreground v. background.</p>

<hr />

<p>166 epochs:</p>

<p><img src="/assets/img/lighting166.png" alt="" /></p>

<hr />

<p>363 epochs:</p>

<p><img src="/assets/img/lighting363.png" alt="" /></p>

<hr />

<p>781 epochs:</p>

<p><img src="/assets/img/lighting781.png" alt="" /></p>

<hr />

<p>982 epochs:</p>

<p><img src="/assets/img/lighting982.png" alt="" /></p>

<hr />

<p>I would like to explore this further as a tool for product design.</p>

  </div>
</article>

          </div>
        </div>
      </div>
    </div>
  </body>
</html>
